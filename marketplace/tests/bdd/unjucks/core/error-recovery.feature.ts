/**
 * HIVE QUEEN BDD Scenarios - Unjucks Error Recovery and Resilience
 * Ultra-robust error handling and system recovery for enterprise production environments
 */

import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import { promises as fs } from 'fs';
import { join } from 'path';
import { tmpdir } from 'os';
import { mkdtemp, rm } from 'fs/promises';
import { EventEmitter } from 'events';

// Error recovery interfaces
interface ErrorRecoveryConfig {
  maxRetries: number;
  retryDelayMs: number;
  backoffStrategy: 'linear' | 'exponential' | 'fixed';
  circuitBreakerThreshold: number;
  healthCheckInterval: number;
  enableFallbackTemplates: boolean;
  enableGracefulDegradation: boolean;
  errorReportingEndpoint?: string;
}

interface TemplateError {
  type: 'syntax' | 'compilation' | 'rendering' | 'io' | 'ontology' | 'dependency';
  severity: 'low' | 'medium' | 'high' | 'critical';
  templatePath: string;
  error: Error;
  timestamp: number;
  context?: any;
  stack?: string;
  recoveryAttempts: number;
  recovered: boolean;
}

interface RecoveryStrategy {
  name: string;
  applicable: (error: TemplateError) => boolean;
  execute: (error: TemplateError, engine: ResilientUnjucksEngine) => Promise<boolean>;
  priority: number;
}

interface SystemHealthStatus {
  overall: 'healthy' | 'degraded' | 'critical' | 'down';
  templateEngine: 'operational' | 'degraded' | 'failed';
  ontologyService: 'operational' | 'degraded' | 'failed';
  fileSystem: 'operational' | 'degraded' | 'failed';
  memoryUsage: number;
  errorRate: number;
  lastHealthCheck: number;
  activeErrors: number;
  recoveredErrors: number;
}

// Resilient template engine with comprehensive error recovery
class ResilientUnjucksEngine extends EventEmitter {
  private config: ErrorRecoveryConfig;
  private errorHistory: Map<string, TemplateError[]> = new Map();
  private recoveryStrategies: RecoveryStrategy[] = [];
  private circuitBreakers: Map<string, { failures: number; lastFailure: number; isOpen: boolean }> = new Map();
  private fallbackTemplates: Map<string, string> = new Map();
  private healthStatus: SystemHealthStatus;
  private healthCheckInterval?: NodeJS.Timeout;
  private gracefulShutdownHandlers: Array<() => Promise<void>> = [];

  constructor(config: ErrorRecoveryConfig) {
    super();
    this.config = config;
    this.healthStatus = {
      overall: 'healthy',
      templateEngine: 'operational',
      ontologyService: 'operational',
      fileSystem: 'operational',
      memoryUsage: 0,
      errorRate: 0,
      lastHealthCheck: Date.now(),
      activeErrors: 0,
      recoveredErrors: 0
    };
    
    this.setupRecoveryStrategies();
    this.setupHealthMonitoring();
    this.setupGracefulShutdown();
  }

  private setupRecoveryStrategies(): void {
    // Strategy 1: Template syntax error recovery
    this.recoveryStrategies.push({
      name: 'SyntaxErrorRecovery',
      priority: 1,
      applicable: (error) => error.type === 'syntax',
      execute: async (error, engine) => {
        console.log(`üîß Attempting syntax error recovery for ${error.templatePath}`);
        
        try {
          // Try to load last known good version
          const backupPath = `${error.templatePath}.backup`;
          const backupExists = await fs.access(backupPath).then(() => true).catch(() => false);
          
          if (backupExists) {
            const backupContent = await fs.readFile(backupPath, 'utf8');
            await fs.writeFile(error.templatePath, backupContent);
            console.log(`‚úÖ Restored from backup: ${error.templatePath}`);
            return true;
          }
          
          // Try to use fallback template
          if (engine.config.enableFallbackTemplates) {
            const fallback = engine.fallbackTemplates.get(error.templatePath);
            if (fallback) {
              await fs.writeFile(error.templatePath, fallback);
              console.log(`‚úÖ Applied fallback template: ${error.templatePath}`);
              return true;
            }
          }
          
          return false;
        } catch (recoveryError) {
          console.error(`‚ùå Syntax recovery failed:`, recoveryError);
          return false;
        }
      }
    });

    // Strategy 2: I/O error recovery with retry
    this.recoveryStrategies.push({
      name: 'IOErrorRecovery',
      priority: 2,
      applicable: (error) => error.type === 'io',
      execute: async (error, engine) => {
        console.log(`üîÑ Attempting I/O error recovery for ${error.templatePath}`);
        
        const maxRetries = engine.config.maxRetries;
        let attempt = 0;
        
        while (attempt < maxRetries) {
          try {
            // Wait with backoff
            const delay = engine.calculateBackoffDelay(attempt);
            await new Promise(resolve => setTimeout(resolve, delay));
            
            // Retry the operation
            await fs.access(error.templatePath);
            const content = await fs.readFile(error.templatePath, 'utf8');
            
            console.log(`‚úÖ I/O recovery succeeded after ${attempt + 1} attempts`);
            return true;
          } catch (retryError) {
            attempt++;
            console.log(`üîÑ I/O retry ${attempt}/${maxRetries} failed`);
          }
        }
        
        console.error(`‚ùå I/O recovery failed after ${maxRetries} attempts`);
        return false;
      }
    });

    // Strategy 3: Ontology service recovery
    this.recoveryStrategies.push({
      name: 'OntologyServiceRecovery',
      priority: 3,
      applicable: (error) => error.type === 'ontology',
      execute: async (error, engine) => {
        console.log(`üß† Attempting ontology service recovery`);
        
        try {
          // Check if ontology service is responsive
          await engine.testOntologyService();
          
          // Reload ontology cache
          await engine.reloadOntologyCache();
          
          console.log(`‚úÖ Ontology service recovered`);
          engine.healthStatus.ontologyService = 'operational';
          return true;
        } catch (recoveryError) {
          console.error(`‚ùå Ontology service recovery failed:`, recoveryError);
          engine.healthStatus.ontologyService = 'failed';
          
          // Enable graceful degradation
          if (engine.config.enableGracefulDegradation) {
            console.log(`üé≠ Enabling graceful degradation mode`);
            await engine.enableGracefulDegradation();
            return true; // Partial recovery
          }
          
          return false;
        }
      }
    });

    // Strategy 4: Memory pressure recovery
    this.recoveryStrategies.push({
      name: 'MemoryPressureRecovery',
      priority: 4,
      applicable: (error) => error.error.message.includes('memory') || error.error.message.includes('heap'),
      execute: async (error, engine) => {
        console.log(`üßπ Attempting memory pressure recovery`);
        
        try {
          // Clear template cache
          await engine.clearTemplateCache();
          
          // Force garbage collection if available
          if (global.gc) {
            global.gc();
          }
          
          // Reduce cache sizes
          await engine.reduceCacheSizes();
          
          console.log(`‚úÖ Memory pressure recovery completed`);
          return true;
        } catch (recoveryError) {
          console.error(`‚ùå Memory recovery failed:`, recoveryError);
          return false;
        }
      }
    });

    // Strategy 5: Dependency resolution recovery
    this.recoveryStrategies.push({
      name: 'DependencyRecovery',
      priority: 5,
      applicable: (error) => error.type === 'dependency',
      execute: async (error, engine) => {
        console.log(`üîó Attempting dependency recovery for ${error.templatePath}`);
        
        try {
          // Rebuild dependency graph
          await engine.rebuildDependencyGraph();
          
          // Check for circular dependencies
          const circular = engine.detectCircularDependencies();
          if (circular.length > 0) {
            console.log(`‚ö†Ô∏è  Detected circular dependencies: ${circular.join(', ')}`);
            await engine.resolveCIrcularDependencies(circular);
          }
          
          console.log(`‚úÖ Dependency recovery completed`);
          return true;
        } catch (recoveryError) {
          console.error(`‚ùå Dependency recovery failed:`, recoveryError);
          return false;
        }
      }
    });

    // Sort strategies by priority
    this.recoveryStrategies.sort((a, b) => a.priority - b.priority);
  }

  private setupHealthMonitoring(): void {
    this.healthCheckInterval = setInterval(async () => {
      try {
        await this.performHealthCheck();
      } catch (error) {
        console.error('Health check failed:', error);
      }
    }, this.config.healthCheckInterval);
  }

  private setupGracefulShutdown(): void {
    const shutdown = async () => {
      console.log('üõë Initiating graceful shutdown...');
      
      // Execute shutdown handlers
      for (const handler of this.gracefulShutdownHandlers) {
        try {
          await handler();
        } catch (error) {
          console.error('Shutdown handler failed:', error);
        }
      }
      
      // Clear health check interval
      if (this.healthCheckInterval) {
        clearInterval(this.healthCheckInterval);
      }
      
      console.log('‚úÖ Graceful shutdown completed');
    };

    process.on('SIGTERM', shutdown);
    process.on('SIGINT', shutdown);
    process.on('uncaughtException', async (error) => {
      console.error('üí• Uncaught exception:', error);
      await this.handleCriticalError(error);
      await shutdown();
      process.exit(1);
    });
  }

  async handleError(templatePath: string, error: Error, context?: any): Promise<boolean> {
    const templateError: TemplateError = {
      type: this.classifyError(error),
      severity: this.assessSeverity(error),
      templatePath,
      error,
      timestamp: Date.now(),
      context,
      stack: error.stack,
      recoveryAttempts: 0,
      recovered: false
    };

    console.log(`üö® Error detected: ${templateError.type} (${templateError.severity}) in ${templatePath}`);
    console.log(`   Error: ${error.message}`);

    // Record error in history
    if (!this.errorHistory.has(templatePath)) {
      this.errorHistory.set(templatePath, []);
    }
    this.errorHistory.get(templatePath)!.push(templateError);

    // Update health status
    this.healthStatus.activeErrors++;
    this.updateHealthStatus(templateError);

    // Check circuit breaker
    if (this.isCircuitBreakerOpen(templatePath)) {
      console.log(`‚ö° Circuit breaker OPEN for ${templatePath} - skipping recovery`);
      this.emit('error', { type: 'circuit-breaker-open', templatePath, error });
      return false;
    }

    // Attempt recovery
    const recovered = await this.attemptRecovery(templateError);
    
    if (recovered) {
      console.log(`‚úÖ Successfully recovered from error in ${templatePath}`);
      templateError.recovered = true;
      this.healthStatus.recoveredErrors++;
      this.healthStatus.activeErrors--;
      this.resetCircuitBreaker(templatePath);
      this.emit('recovery', templateError);
    } else {
      console.log(`‚ùå Failed to recover from error in ${templatePath}`);
      this.incrementCircuitBreaker(templatePath);
      this.emit('recovery-failed', templateError);
    }

    // Report error if endpoint configured
    if (this.config.errorReportingEndpoint) {
      await this.reportError(templateError).catch(console.warn);
    }

    return recovered;
  }

  private classifyError(error: Error): TemplateError['type'] {
    const message = error.message.toLowerCase();
    
    if (message.includes('syntax') || message.includes('parse')) {
      return 'syntax';
    } else if (message.includes('compile')) {
      return 'compilation';
    } else if (message.includes('render')) {
      return 'rendering';
    } else if (message.includes('enoent') || message.includes('eacces') || message.includes('file')) {
      return 'io';
    } else if (message.includes('ontology') || message.includes('sparql') || message.includes('rdf')) {
      return 'ontology';
    } else if (message.includes('dependency') || message.includes('circular') || message.includes('import')) {
      return 'dependency';
    }
    
    return 'io'; // Default classification
  }

  private assessSeverity(error: Error): TemplateError['severity'] {
    const message = error.message.toLowerCase();
    
    if (message.includes('critical') || message.includes('fatal')) {
      return 'critical';
    } else if (message.includes('out of memory') || message.includes('heap')) {
      return 'critical';
    } else if (message.includes('permission') || message.includes('eacces')) {
      return 'high';
    } else if (message.includes('syntax') || message.includes('compile')) {
      return 'medium';
    }
    
    return 'low';
  }

  private async attemptRecovery(templateError: TemplateError): Promise<boolean> {
    console.log(`üîß Starting recovery process for ${templateError.templatePath}`);
    
    // Find applicable recovery strategies
    const applicableStrategies = this.recoveryStrategies.filter(strategy => 
      strategy.applicable(templateError)
    );
    
    if (applicableStrategies.length === 0) {
      console.log(`‚ùå No applicable recovery strategies found`);
      return false;
    }
    
    // Try each strategy in priority order
    for (const strategy of applicableStrategies) {
      console.log(`üîß Trying recovery strategy: ${strategy.name}`);
      templateError.recoveryAttempts++;
      
      try {
        const success = await strategy.execute(templateError, this);
        if (success) {
          console.log(`‚úÖ Recovery strategy ${strategy.name} succeeded`);
          return true;
        } else {
          console.log(`‚ùå Recovery strategy ${strategy.name} failed`);
        }
      } catch (recoveryError) {
        console.error(`üí• Recovery strategy ${strategy.name} threw error:`, recoveryError);
      }
    }
    
    console.log(`‚ùå All recovery strategies exhausted`);
    return false;
  }

  private calculateBackoffDelay(attempt: number): number {
    const baseDelay = this.config.retryDelayMs;
    
    switch (this.config.backoffStrategy) {
      case 'linear':
        return baseDelay * (attempt + 1);
      case 'exponential':
        return baseDelay * Math.pow(2, attempt);
      case 'fixed':
      default:
        return baseDelay;
    }
  }

  private isCircuitBreakerOpen(templatePath: string): boolean {
    const breaker = this.circuitBreakers.get(templatePath);
    if (!breaker) return false;
    
    return breaker.isOpen && (Date.now() - breaker.lastFailure) < 60000; // 1 minute cooldown
  }

  private incrementCircuitBreaker(templatePath: string): void {
    if (!this.circuitBreakers.has(templatePath)) {
      this.circuitBreakers.set(templatePath, { failures: 0, lastFailure: 0, isOpen: false });
    }
    
    const breaker = this.circuitBreakers.get(templatePath)!;
    breaker.failures++;
    breaker.lastFailure = Date.now();
    
    if (breaker.failures >= this.config.circuitBreakerThreshold) {
      breaker.isOpen = true;
      console.log(`‚ö° Circuit breaker OPENED for ${templatePath} (${breaker.failures} failures)`);
    }
  }

  private resetCircuitBreaker(templatePath: string): void {
    const breaker = this.circuitBreakers.get(templatePath);
    if (breaker) {
      breaker.failures = 0;
      breaker.isOpen = false;
      console.log(`‚ö° Circuit breaker RESET for ${templatePath}`);
    }
  }

  private updateHealthStatus(templateError: TemplateError): void {
    // Update component-specific health
    switch (templateError.type) {
      case 'ontology':
        this.healthStatus.ontologyService = templateError.severity === 'critical' ? 'failed' : 'degraded';
        break;
      case 'io':
        this.healthStatus.fileSystem = templateError.severity === 'critical' ? 'failed' : 'degraded';
        break;
      default:
        this.healthStatus.templateEngine = templateError.severity === 'critical' ? 'failed' : 'degraded';
    }
    
    // Update overall health
    const components = [this.healthStatus.templateEngine, this.healthStatus.ontologyService, this.healthStatus.fileSystem];
    const failedComponents = components.filter(c => c === 'failed').length;
    const degradedComponents = components.filter(c => c === 'degraded').length;
    
    if (failedComponents > 0) {
      this.healthStatus.overall = failedComponents >= 2 ? 'down' : 'critical';
    } else if (degradedComponents > 0) {
      this.healthStatus.overall = 'degraded';
    } else {
      this.healthStatus.overall = 'healthy';
    }
  }

  private async performHealthCheck(): Promise<void> {
    const startTime = performance.now();
    
    try {
      // Check memory usage
      const memoryUsage = process.memoryUsage();
      this.healthStatus.memoryUsage = memoryUsage.heapUsed / 1024 / 1024; // MB
      
      // Calculate error rate
      const totalErrors = Array.from(this.errorHistory.values()).flat().length;
      const recentErrors = Array.from(this.errorHistory.values())
        .flat()
        .filter(e => Date.now() - e.timestamp < 60000).length; // Last minute
      
      this.healthStatus.errorRate = recentErrors;
      this.healthStatus.lastHealthCheck = Date.now();
      
      // Test basic functionality
      await this.testBasicFunctionality();
      
      const healthCheckDuration = performance.now() - startTime;
      
      this.emit('health-check', {
        status: this.healthStatus,
        duration: healthCheckDuration
      });
      
    } catch (error) {
      console.error('Health check failed:', error);
      this.healthStatus.overall = 'critical';
    }
  }

  private async testBasicFunctionality(): Promise<void> {
    // Test template rendering capability
    try {
      await this.renderTemplate('test', { test: true });
      if (this.healthStatus.templateEngine === 'failed') {
        this.healthStatus.templateEngine = 'operational';
      }
    } catch (error) {
      this.healthStatus.templateEngine = 'failed';
    }
    
    // Test ontology service
    try {
      await this.testOntologyService();
      if (this.healthStatus.ontologyService === 'failed') {
        this.healthStatus.ontologyService = 'operational';
      }
    } catch (error) {
      this.healthStatus.ontologyService = 'failed';
    }
  }

  private async testOntologyService(): Promise<void> {
    // Mock ontology service test
    return new Promise((resolve, reject) => {
      setTimeout(() => {
        if (Math.random() > 0.9) { // 10% chance of failure for testing
          reject(new Error('Ontology service timeout'));
        } else {
          resolve();
        }
      }, 100);
    });
  }

  private async reloadOntologyCache(): Promise<void> {
    // Mock ontology cache reload
    console.log('üîÑ Reloading ontology cache...');
    await new Promise(resolve => setTimeout(resolve, 200));
    console.log('‚úÖ Ontology cache reloaded');
  }

  private async enableGracefulDegradation(): Promise<void> {
    console.log('üé≠ Enabling graceful degradation mode...');
    // Switch to cached ontology data, disable real-time updates
    this.healthStatus.ontologyService = 'degraded';
  }

  private async clearTemplateCache(): Promise<void> {
    console.log('üßπ Clearing template cache...');
    // Mock cache clearing
  }

  private async reduceCacheSizes(): Promise<void> {
    console.log('üìâ Reducing cache sizes...');
    // Mock cache size reduction
  }

  private async rebuildDependencyGraph(): Promise<void> {
    console.log('üîó Rebuilding dependency graph...');
    // Mock dependency graph rebuild
  }

  private detectCircularDependencies(): string[] {
    // Mock circular dependency detection
    return [];
  }

  private async resolveCIrcularDependencies(circular: string[]): Promise<void> {
    console.log(`üîÑ Resolving circular dependencies: ${circular.join(', ')}`);
    // Mock circular dependency resolution
  }

  private async reportError(templateError: TemplateError): Promise<void> {
    // Mock error reporting to external service
    console.log(`üìä Reporting error to ${this.config.errorReportingEndpoint}`);
  }

  private async handleCriticalError(error: Error): Promise<void> {
    console.log('üí• Handling critical system error...');
    this.healthStatus.overall = 'down';
    this.emit('critical-error', error);
  }

  async renderTemplate(templatePath: string, context: any): Promise<string> {
    try {
      // Mock template rendering that can fail
      if (templatePath.includes('error')) {
        throw new Error('Template rendering failed');
      }
      
      return `<!-- Rendered ${templatePath} -->`;
    } catch (error) {
      const recovered = await this.handleError(templatePath, error as Error, context);
      
      if (!recovered) {
        throw error;
      }
      
      // Return fallback or recovered result
      return `<!-- Fallback render for ${templatePath} -->`;
    }
  }

  getHealthStatus(): SystemHealthStatus {
    return { ...this.healthStatus };
  }

  getErrorHistory(templatePath?: string): TemplateError[] {
    if (templatePath) {
      return this.errorHistory.get(templatePath) || [];
    }
    
    return Array.from(this.errorHistory.values()).flat();
  }

  addGracefulShutdownHandler(handler: () => Promise<void>): void {
    this.gracefulShutdownHandlers.push(handler);
  }

  async destroy(): Promise<void> {
    console.log('üõë Destroying resilient engine...');
    
    if (this.healthCheckInterval) {
      clearInterval(this.healthCheckInterval);
    }
    
    this.removeAllListeners();
    this.errorHistory.clear();
    this.circuitBreakers.clear();
    this.fallbackTemplates.clear();
    
    console.log('‚úÖ Resilient engine destroyed');
  }
}

describe('HIVE QUEEN BDD: Unjucks Error Recovery and Resilience', () => {
  let resilientEngine: ResilientUnjucksEngine;
  let tempDir: string;

  beforeEach(async () => {
    tempDir = await mkdtemp(join(tmpdir(), 'error-recovery-'));
    
    const config: ErrorRecoveryConfig = {
      maxRetries: 3,
      retryDelayMs: 100,
      backoffStrategy: 'exponential',
      circuitBreakerThreshold: 3,
      healthCheckInterval: 1000,
      enableFallbackTemplates: true,
      enableGracefulDegradation: true,
      errorReportingEndpoint: 'https://monitoring.example.com/errors'
    };
    
    resilientEngine = new ResilientUnjucksEngine(config);
  });

  afterEach(async () => {
    await resilientEngine.destroy();
    await rm(tempDir, { recursive: true, force: true });
  });

  describe('FEATURE: Comprehensive Error Classification and Handling', () => {
    describe('SCENARIO: Handle template syntax errors with automatic recovery', () => {
      it('GIVEN template with syntax error WHEN rendering THEN recovers using backup', async () => {
        // GIVEN: Template with backup
        const templatePath = join(tempDir, 'syntax-error.njk');
        const backupPath = `${templatePath}.backup`;
        
        const validTemplate = `<div>{{ content }}</div>`;
        const invalidTemplate = `<div>{{ unclosed.expression`;
        
        await fs.writeFile(backupPath, validTemplate);
        await fs.writeFile(templatePath, invalidTemplate);

        // Set up recovery listener
        const recoveryPromise = new Promise<TemplateError>((resolve) => {
          resilientEngine.once('recovery', (error) => resolve(error));
        });

        // WHEN: Attempt to render invalid template
        const result = await resilientEngine.renderTemplate(templatePath, { content: 'test' });

        // THEN: Error is handled and recovery occurs
        expect(result).toBeDefined();
        const recoveredError = await recoveryPromise;
        expect(recoveredError.recovered).toBe(true);
        expect(recoveredError.type).toBe('syntax');
        expect(recoveredError.recoveryAttempts).toBeGreaterThan(0);
        
        // Verify backup was restored
        const restoredContent = await fs.readFile(templatePath, 'utf8');
        expect(restoredContent).toBe(validTemplate);
      });

      it('GIVEN repeated syntax errors WHEN circuit breaker threshold reached THEN stops attempting recovery', async () => {
        // GIVEN: Template that always fails
        const templatePath = join(tempDir, 'always-fails.njk');
        await fs.writeFile(templatePath, '{{ invalid syntax');

        const circuitBreakerPromise = new Promise<any>((resolve) => {
          resilientEngine.once('error', (event) => {
            if (event.type === 'circuit-breaker-open') {
              resolve(event);
            }
          });
        });

        // WHEN: Trigger failures to reach circuit breaker threshold
        for (let i = 0; i < 4; i++) {
          try {
            await resilientEngine.renderTemplate(templatePath, {});
          } catch (error) {
            // Expected failures
          }
        }

        // THEN: Circuit breaker opens
        const circuitBreakerEvent = await circuitBreakerPromise;
        expect(circuitBreakerEvent.type).toBe('circuit-breaker-open');
        expect(circuitBreakerEvent.templatePath).toBe(templatePath);
      });
    });

    describe('SCENARIO: Handle I/O errors with exponential backoff retry', () => {
      it('GIVEN file system error WHEN retrying with backoff THEN eventually succeeds', async () => {
        // GIVEN: Mock file system error that resolves after retries
        const templatePath = join(tempDir, 'io-error.njk');
        await fs.writeFile(templatePath, 'template content');
        
        let attemptCount = 0;
        const originalReadFile = fs.readFile;
        
        // Mock fs.readFile to fail first 2 times, then succeed
        vi.spyOn(fs, 'readFile').mockImplementation((async (path: any, encoding: any) => {
          if (path === templatePath) {
            attemptCount++;
            if (attemptCount <= 2) {
              throw new Error('ENOENT: no such file or directory');
            }
          }
          return originalReadFile(path, encoding);
        }) as any);

        const recoveryPromise = new Promise<TemplateError>((resolve) => {
          resilientEngine.once('recovery', (error) => resolve(error));
        });

        // WHEN: Trigger I/O error
        const mockError = new Error('ENOENT: no such file or directory');
        const recovered = await resilientEngine.handleError(templatePath, mockError);

        // THEN: Error recovered after retries
        expect(recovered).toBe(true);
        const recoveredError = await recoveryPromise;
        expect(recoveredError.type).toBe('io');
        expect(attemptCount).toBeGreaterThan(2);
        
        vi.restoreAllMocks();
      });

      it('GIVEN persistent I/O error WHEN max retries exceeded THEN reports failure', async () => {
        // GIVEN: Persistent file system error
        const templatePath = join(tempDir, 'persistent-error.njk');
        
        const failurePromise = new Promise<TemplateError>((resolve) => {
          resilientEngine.once('recovery-failed', (error) => resolve(error));
        });

        // WHEN: Trigger persistent I/O error
        const persistentError = new Error('EACCES: permission denied');
        const recovered = await resilientEngine.handleError(templatePath, persistentError);

        // THEN: Recovery fails after max attempts
        expect(recovered).toBe(false);
        const failedError = await failurePromise;
        expect(failedError.type).toBe('io');
        expect(failedError.recovered).toBe(false);
      });
    });
  });

  describe('FEATURE: System Health Monitoring', () => {
    describe('SCENARIO: Continuous health monitoring with component status', () => {
      it('GIVEN healthy system WHEN monitoring THEN reports all components operational', async () => {
        // GIVEN: Wait for initial health check
        const healthPromise = new Promise<any>((resolve) => {
          resilientEngine.once('health-check', (event) => resolve(event));
        });

        // WHEN: Health check occurs
        const healthEvent = await healthPromise;

        // THEN: System reports healthy status
        expect(healthEvent.status.overall).toBe('healthy');
        expect(healthEvent.status.templateEngine).toBe('operational');
        expect(healthEvent.status.ontologyService).toBe('operational');
        expect(healthEvent.status.fileSystem).toBe('operational');
        expect(healthEvent.status.memoryUsage).toBeGreaterThan(0);
        expect(healthEvent.duration).toBeGreaterThan(0);
      });

      it('GIVEN system with errors WHEN health check runs THEN reports degraded status', async () => {
        // GIVEN: Introduce errors to degrade system health
        const templatePath = join(tempDir, 'health-test.njk');
        const ontologyError = new Error('Ontology service timeout');
        
        // Trigger error to affect health
        await resilientEngine.handleError(templatePath, ontologyError);
        
        // WHEN: Get health status
        const healthStatus = resilientEngine.getHealthStatus();

        // THEN: Health reflects system degradation
        expect(healthStatus.activeErrors).toBeGreaterThan(0);
        expect(healthStatus.overall).not.toBe('healthy');
      });
    });
  });

  describe('FEATURE: Graceful Degradation', () => {
    describe('SCENARIO: Enable degraded mode when critical services fail', () => {
      it('GIVEN ontology service failure WHEN graceful degradation enabled THEN continues with limited functionality', async () => {
        // GIVEN: Ontology service failure
        const templatePath = join(tempDir, 'degradation-test.njk');
        const criticalOntologyError = new Error('Critical ontology service failure');
        
        const recoveryPromise = new Promise<TemplateError>((resolve) => {
          resilientEngine.once('recovery', (error) => resolve(error));
        });

        // WHEN: Handle critical ontology error with graceful degradation
        const recovered = await resilientEngine.handleError(templatePath, criticalOntologyError);

        // THEN: System recovers in degraded mode
        expect(recovered).toBe(true); // Partial recovery
        const recoveredError = await recoveryPromise;
        expect(recoveredError.recovered).toBe(true);
        
        const healthStatus = resilientEngine.getHealthStatus();
        expect(healthStatus.ontologyService).toBe('degraded');
        expect(healthStatus.overall).toBe('degraded');
      });
    });
  });

  describe('FEATURE: Memory Management and Pressure Relief', () => {
    describe('SCENARIO: Recover from memory pressure situations', () => {
      it('GIVEN memory pressure error WHEN recovery triggered THEN clears caches and recovers', async () => {
        // GIVEN: Simulate memory pressure
        const templatePath = join(tempDir, 'memory-test.njk');
        const memoryError = new Error('JavaScript heap out of memory');
        
        const recoveryPromise = new Promise<TemplateError>((resolve) => {
          resilientEngine.once('recovery', (error) => resolve(error));
        });

        // WHEN: Handle memory pressure error
        const recovered = await resilientEngine.handleError(templatePath, memoryError);

        // THEN: Memory recovery strategy executed
        expect(recovered).toBe(true);
        const recoveredError = await recoveryPromise;
        expect(recoveredError.type).toBe('io'); // Classified as I/O due to message content
        expect(recoveredError.recovered).toBe(true);
      });
    });
  });

  describe('FEATURE: Error History and Analytics', () => {
    describe('SCENARIO: Track error patterns and recovery success rates', () => {
      it('GIVEN multiple errors over time WHEN analyzing history THEN provides comprehensive error analytics', async () => {
        // GIVEN: Generate various types of errors
        const templatePath1 = join(tempDir, 'error1.njk');
        const templatePath2 = join(tempDir, 'error2.njk');
        
        const errors = [
          { path: templatePath1, error: new Error('Syntax error in template') },
          { path: templatePath1, error: new Error('Compilation failed') },
          { path: templatePath2, error: new Error('ENOENT: file not found') },
          { path: templatePath2, error: new Error('Ontology service down') }
        ];

        // WHEN: Handle multiple errors
        const recoveryResults = [];
        for (const { path, error } of errors) {
          const recovered = await resilientEngine.handleError(path, error);
          recoveryResults.push(recovered);
        }

        // THEN: Error history provides comprehensive analytics
        const allErrors = resilientEngine.getErrorHistory();
        const template1Errors = resilientEngine.getErrorHistory(templatePath1);
        const template2Errors = resilientEngine.getErrorHistory(templatePath2);
        
        expect(allErrors.length).toBe(4);
        expect(template1Errors.length).toBe(2);
        expect(template2Errors.length).toBe(2);
        
        // Verify error classification
        const syntaxErrors = allErrors.filter(e => e.type === 'syntax');
        const ioErrors = allErrors.filter(e => e.type === 'io');
        const ontologyErrors = allErrors.filter(e => e.type === 'ontology');
        
        expect(syntaxErrors.length).toBeGreaterThan(0);
        expect(ioErrors.length).toBeGreaterThan(0);
        expect(ontologyErrors.length).toBeGreaterThan(0);
        
        // Verify recovery attempts were made
        allErrors.forEach(error => {
          expect(error.recoveryAttempts).toBeGreaterThanOrEqual(1);
          expect(error.timestamp).toBeGreaterThan(0);
        });
      });
    });
  });

  describe('FEATURE: Critical Error Handling', () => {
    describe('SCENARIO: Handle system-wide critical failures', () => {
      it('GIVEN uncaught exception WHEN critical error handler triggered THEN gracefully shuts down', async () => {
        // GIVEN: Set up critical error listener
        const criticalErrorPromise = new Promise<Error>((resolve) => {
          resilientEngine.once('critical-error', (error) => resolve(error));
        });
        
        let shutdownHandlerCalled = false;
        resilientEngine.addGracefulShutdownHandler(async () => {
          shutdownHandlerCalled = true;
        });

        // WHEN: Trigger critical error
        const criticalError = new Error('Critical system failure');
        await resilientEngine['handleCriticalError'](criticalError);

        // THEN: Critical error handling occurs
        const handledError = await criticalErrorPromise;
        expect(handledError.message).toBe('Critical system failure');
        
        const healthStatus = resilientEngine.getHealthStatus();
        expect(healthStatus.overall).toBe('down');
      });
    });
  });

  describe('FEATURE: Production Resilience Patterns', () => {
    describe('SCENARIO: Handle real-world production failure scenarios', () => {
      it('GIVEN cascading failure scenario WHEN multiple systems fail THEN isolates failures and maintains partial service', async () => {
        // GIVEN: Simulate cascading failures (ontology -> templates -> file system)
        const templates = [
          join(tempDir, 'service1.njk'),
          join(tempDir, 'service2.njk'),
          join(tempDir, 'service3.njk')
        ];
        
        const cascadingErrors = [
          new Error('Ontology service connection timeout'),
          new Error('Template compilation failed due to missing ontology'),
          new Error('EACCES: permission denied accessing template files')
        ];

        const recoveryEvents: TemplateError[] = [];
        const failureEvents: TemplateError[] = [];
        
        resilientEngine.on('recovery', (error) => recoveryEvents.push(error));
        resilientEngine.on('recovery-failed', (error) => failureEvents.push(error));

        // WHEN: Handle cascading failures
        const recoveryResults = [];
        for (let i = 0; i < templates.length; i++) {
          const recovered = await resilientEngine.handleError(templates[i], cascadingErrors[i]);
          recoveryResults.push(recovered);
          
          // Small delay to simulate real-time cascading
          await new Promise(resolve => setTimeout(resolve, 50));
        }

        // THEN: System handles cascading failures gracefully
        expect(recoveryEvents.length + failureEvents.length).toBe(3);
        
        // At least some recoveries should succeed (graceful degradation)
        const successfulRecoveries = recoveryEvents.filter(e => e.recovered).length;
        expect(successfulRecoveries).toBeGreaterThanOrEqual(1);
        
        // System should still be responsive
        const healthStatus = resilientEngine.getHealthStatus();
        expect(healthStatus.overall).not.toBe('down'); // Should maintain some level of service
        
        console.log(`Cascading failure handling:`);
        console.log(`  Successful recoveries: ${successfulRecoveries}/3`);
        console.log(`  System health: ${healthStatus.overall}`);
        console.log(`  Active errors: ${healthStatus.activeErrors}`);
        console.log(`  Recovered errors: ${healthStatus.recoveredErrors}`);
      });
    });
  });
});
